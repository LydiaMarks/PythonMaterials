{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "710d0bff-5f42-44cd-b19f-ea951b1dce1c",
   "metadata": {},
   "source": [
    "# Lab 1\n",
    "\n",
    "We will do text analysis of a public free text to demonstrate text analysis techniques.\n",
    "\n",
    "Project Gutenberg is a great resource for these texts.\n",
    "\n",
    "We will use [The Land That Time Forgot](https://www.gutenberg.org/ebooks/551) and download the [TXT version](https://www.gutenberg.org/ebooks/551.txt.utf-8), which we have included in the support files for this training.\n",
    "\n",
    "Take a look at the file and understand the spacing and formatting of the text.\n",
    "\n",
    "There's a boilerplate at the beginning that describes the document and the license at the end for using the text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c37bfc-fa6d-4da9-a4ca-4f02690d9c58",
   "metadata": {},
   "source": [
    "## Count the words of the text\n",
    "\n",
    "We want to count the number of words in the text of the book. \n",
    "\n",
    "To do this we'll split the text on key phrases present in the text.\n",
    "\n",
    "To separate the header from the text, use the phrase\n",
    "`*** START OF THE PROJECT GUTENBERG EBOOK THE LAND THAT TIME FORGOT ***`\n",
    "\n",
    "To separate the text from the license, use the phrase\n",
    "`End of Project Gutenberg's The Land That Time Forgot, by Edgar Rice Burroughs`\n",
    "\n",
    "Since we only want to count words, we'll need to use regular expressions to remove punctuation and quote characters.\n",
    "The only characters we want to keep are alphabetic characters a-z and A-Z.\n",
    "\n",
    "Here is the overview of the steps we're going to take\n",
    "\n",
    "1. Import the `re` module\n",
    "2. Read in the file from the `./support_files/datasets/land_time_forgot.txt` path\n",
    "3. Split the file into the header and the remainder of the text\n",
    "4. Split the remainder into the text and the license\n",
    "5. Parse the lines from the text one by one and only keep alphanumeric characters\n",
    "6. Split the line into words and store the words in an array\n",
    "7. Print the length of the array to find the number of words\n",
    "\n",
    "Start with steps 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d7f34fa-87db-42d4-9959-2db74bab3325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load re\n",
    "import re\n",
    "\n",
    "# open the file and read it into a variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a226b6-3ad3-47cc-bd5e-5ef011fad19c",
   "metadata": {},
   "source": [
    "What questions can you ask about this data?\n",
    "\n",
    "- How many lines are there in the total file?\n",
    "- How many characters?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57d37528-bc1d-4939-a89f-0fc96848bfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# How many lines in total are there?\n",
    "\n",
    "# How many characters are there?\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3408b4c-b823-4208-88d0-f8e2e7f7e910",
   "metadata": {},
   "source": [
    "## Split the file into sections\n",
    "\n",
    "Split the file into the header, the text, and the license\n",
    "\n",
    "If you've used readlines or split the text into lines for the previous question, make sure to [join](https://www.w3schools.com/python/ref_string_join.asp) the lines together.\n",
    "\n",
    "We want to remove all of the extra new lines before we join the text together again.\n",
    "\n",
    "We'l use sub for this purpose with the newline character `\\n` and the `+` to make it replace all repeating characters.\n",
    "\n",
    "```\n",
    "re.sub(r'\\n+', '\\n', TEXT)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a890bf69-f3f8-4307-985e-93a184de2fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# header key phrase\n",
    "header_phrase = \"*** START OF THE PROJECT GUTENBERG EBOOK THE LAND THAT TIME FORGOT ***\"\n",
    "\n",
    "# license key phrase\n",
    "license_phrase = \"End of Project Gutenberg's The Land That Time Forgot, by Edgar Rice Burroughs\"\n",
    "\n",
    "# join the lines\n",
    "\n",
    "# separate the header from the rest of the text\n",
    "\n",
    "# separate the text from the license\n",
    "\n",
    "# remove the extra newlines\n",
    "\n",
    "# how many lines is the text ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edbd708-11be-4f38-8f92-2b7185990526",
   "metadata": {},
   "source": [
    "## Verify your work\n",
    "\n",
    "Look at the first 10 lines of the file.  What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50093388-3221-475b-994b-36480a479f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 10 lines of the file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92211229-ff6e-4610-bbc2-2cfc31b34869",
   "metadata": {},
   "source": [
    "**Eek!**\n",
    "\n",
    "What we see is that there are some header lines still present in the text.\n",
    "\n",
    "We want to remove the empty lines, the Produced by value, and the title and author information.\n",
    "\n",
    "We will keep the chapter information.\n",
    "\n",
    "How many lines do you have to remove from the front of the array?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4041387a-fbc0-449b-8e47-426d7fc3bc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the rest of the header information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3efc36d-c09a-40b7-a5e8-4f92da764c6a",
   "metadata": {},
   "source": [
    "## Clean up the text\n",
    "\n",
    "We want to get the words from the text file. This means only keeping the alphanumeric characters, so use the `sub` function again to only keep those characters.\n",
    "\n",
    "```\n",
    "re.sub('[^a-zA-Z]', '', TEXT)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8382b31f-90ba-4471-b21b-d70108f0a846",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define your array of words\n",
    "\n",
    "# go through all of the lines\n",
    "\n",
    "    # keep only the alphanumeric characters\n",
    "    \n",
    "    # split the line by space and add the words onto our array\n",
    "    \n",
    "\n",
    "\n",
    "# look at the first 15 words to verify\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef5ecce-9dcc-4d03-b0a4-7abd1720aa62",
   "metadata": {},
   "source": [
    "## Additional cleaning\n",
    "\n",
    "The first word is now `Chapter` but there is no number.  We know that there are several of these extraneous words throughout the text.  \n",
    "\n",
    "What other words would you remove from the text?\n",
    "\n",
    "Let's create an array of words that we know from looking at the text shouldn't be counted.\n",
    "\n",
    "Then print the number of words in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5b6d248-4df8-4b2b-874d-8951900509e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words is {0:6,d}.\n"
     ]
    }
   ],
   "source": [
    "# create a list of words to skip\n",
    "skip_words = ['Chapter']\n",
    "\n",
    "# create a list that holds the updated text\n",
    "\n",
    "\n",
    "# go through each word in the list\n",
    "\n",
    "    # if it's not in the list to be skipped\n",
    "    \n",
    "        # add the word to the new list\n",
    "        \n",
    "\n",
    "# print the number of words with a formatted number\n",
    "print('Total number of words is {0:6,d}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2b9332-726d-4261-b516-31145f8dd162",
   "metadata": {},
   "source": [
    "## Data cleanliness\n",
    "\n",
    "When you look at the full text of the book and then the list of words, you will find discrepancies or places where you might disagree with the way the words have been split.  For example, in the first 15 lines there are the three words `three` `o` `clock`.  \n",
    "\n",
    "Are these really 3 different words or would you combine `o` and `clock` into one word?\n",
    "\n",
    "When you're analyzing your real data, you'll need to develop hypotheses and rules to clean your data without doing too much to alter the stringency of your analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4bdf72-4e9b-4a8e-b153-67e85bf57fc5",
   "metadata": {},
   "source": [
    "# Word count\n",
    "\n",
    "What is the word that appears most frequently in the text?\n",
    "\n",
    "1. Create a dictionary to store the word as the key and the count as the value\n",
    "2. Go through all of the words\n",
    "3. If the word exists in the dictionary, increment the count\n",
    "4. If the word does not exist, set the count to 1\n",
    "\n",
    "We'll then look at a specific value for a word.  See how many times \"It\" appears in the dictionary\n",
    "\n",
    "Use `get` to find the value.\n",
    "\n",
    "5. Get the max value by using max with a key that indicates it should use `get` for to find the value\n",
    "6. Get the count from the dictionary for the max word\n",
    "7. Print the word and count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d3c4c21-0fdd-40bd-8f8c-2eb3aeace152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word It appears {0:2d} times\n",
      "The word that appears most frequently is \"{0:s}\" ({1:5,d} times)\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary\n",
    "\n",
    "\n",
    "# go through all the words\n",
    "\n",
    "    # check if the word is NOT in the dictionary\n",
    "    \n",
    "        # set the word in the dictionary to be 1\n",
    "       \n",
    "    # else\n",
    "   \n",
    "        # increment the count of the word\n",
    "        \n",
    "\n",
    "# get the value for \"It\"\n",
    "print('The word It appears {0:2d} times')\n",
    "\n",
    "# use max with a key function that gets the dictionary value\n",
    "\n",
    "\n",
    "# get the max_count\n",
    "\n",
    "print('The word that appears most frequently is \"{0:s}\" ({1:5,d} times)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6100ca-1a95-44d6-8b2a-c48068a07c3f",
   "metadata": {},
   "source": [
    "## Which words appear the least frequently?\n",
    "\n",
    "Use the `min` method to find the lowest number of times a word appears\n",
    "\n",
    "1. Get the minimum number\n",
    "2. Go through the dictionary\n",
    "3. Check if the count of the key matches the minimum number\n",
    "4. Add the word to the list if it does\n",
    "5. Print the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc08c8a8-a304-4e86-849c-8d299e99c475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum number of times a word appears in the book is {}. There are {} words with that frequency.\n"
     ]
    }
   ],
   "source": [
    "# Get the minimum frequency (hint: use values)\n",
    "\n",
    "\n",
    "# create a list to store the words\n",
    "\n",
    "\n",
    "# Go through all of the word counts (hint: use 'items')\n",
    "\n",
    "    # check if the value matches the frequency\n",
    "    \n",
    "        # add it to the list if it does\n",
    "        \n",
    "\n",
    "# Print a sentence of the minimum frequency and the number of words with that frequency\n",
    "print('The minimum number of times a word appears in the book is {}. There are {} words with that frequency.'\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d87158b-936c-447b-92b4-bedb68651106",
   "metadata": {},
   "source": [
    "## Stopwords\n",
    "\n",
    "The word that appears the most times is 'the' which is considered a stopword in sentiment analysis.  This word isn't useful to give you an idea of what the text is about so when we do analysis we want to remove these kinds of words.\n",
    "\n",
    "1. Go through the list of stopwords\n",
    "2. remove them from the dictionary of word counts\n",
    "3. find the new word that occurs most frequently\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0353396f-b0d8-4e3c-be75-0958d01d7222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word that appears most frequently is \"{0:s}\" ({1:5,d} times)\n"
     ]
    }
   ],
   "source": [
    "# stopwords\n",
    "stopwords = [\"a\", \"A\", \"an\", \"and\", \"are\", \"as\", \"at\", \"be\", \"but\", \"for\", \"from\", \"had\", \"have\", \"he\", \"her\", \"his\", \"if\", \"in\", \"it\", \"I\", \"into\", \"me\", \"my\", \n",
    "             \"of\", \"on\", \"not\", \"she\", \"that\", \"the\", \"to\", \"was\", \"which\", \"we\", \"were\", \"with\", \"upon\", \"us\"]\n",
    "\n",
    "# go through the list\n",
    "\n",
    "    # if the stopword is in the dictionary of word counts\n",
    "    \n",
    "        # remove the word from the dictionary\n",
    "        \n",
    "\n",
    "# get the max key of the word counts again\n",
    "\n",
    "\n",
    "# get the count of the key\n",
    "\n",
    "# print the key and value\n",
    "print('The word that appears most frequently is \"{0:s}\" ({1:5,d} times)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4163a3a-6eaf-417f-b304-485590625149",
   "metadata": {},
   "source": [
    "## Number of unique words\n",
    "\n",
    "How many unique words are there in the book?\n",
    "\n",
    "Use a `set` to figure this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d326cd0-6edc-4563-abd9-409e1fbac03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This book has {} total words and {} unique words.\n",
      "The percentage of unique words in the book: %.1f\n"
     ]
    }
   ],
   "source": [
    "# create a set from the words\n",
    "\n",
    "\n",
    "# print the number of words\n",
    "print('This book has {} total words and {} unique words.')\n",
    "\n",
    "# Print a sentence of the percentage of words that are unique in the book (hint: use :.1f in your format)\n",
    "# number of unique words\n",
    " \n",
    "# number of words\n",
    " \n",
    "# get the percentage\n",
    " \n",
    "print('The percentage of unique words in the book: %.1f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ca4f73-329d-44e6-9043-b348470d8ecb",
   "metadata": {},
   "source": [
    "# Header information\n",
    "\n",
    "Let's examine the header data and identify information using regular expressions.\n",
    "\n",
    "There is a set of lines in the header that have the `Title`, `Author`, `Release date`, and `Language`.\n",
    "\n",
    "Use [search()](https://docs.python.org/3/library/re.html#re.search) to find the data for these fields.\n",
    "\n",
    "You will need to use non-greedy matching to only match the single line\n",
    "\n",
    "https://www.pythoncheatsheet.org/cheatsheet/regular-expressions#greedy-and-non-greedy-matching\n",
    "\n",
    "Make sure the date is just the month, date, and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0b85fcdd-8914-4b1d-a9b8-61d259d13b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffThe Project Gutenberg eBook of The Land That Time Forgot\\n    \\nThis ebook is for the use of anyone anywhere in the United States and\\nmost other parts of the world at no cost and with almost no restrictions\\nwhatsoever. You may copy it, give it away or re-use it under the terms\\nof the Project Gutenberg License included with this ebook or online\\nat www.gutenberg.org. If you are not located in the United States,\\nyou will have to check the laws of the country where you are located\\nbefore using this eBook.\\n\\nTitle: The Land That Time Forgot\\n\\nAuthor: Edgar Rice Burroughs\\n\\nRelease date: June 1, 1996 [eBook #551]\\n                Most recently updated: January 1, 2021\\n\\nLanguage: English\\n\\nCredits: Produced by Judith Boss.  HTML version by Al Haines.\\n\\n\\n'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b79408c-307f-4506-89d8-da2ee068813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# compile a pattern to match Title (hint: non greedy matching)\n",
    " \n",
    "# use the pattern to search\n",
    " \n",
    "# get the first group\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04aa3508-d163-412d-be75-2a1c02f6bc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile a pattern to match Author (hint: non greedy matching)\n",
    "\n",
    "# use the pattern to search\n",
    " \n",
    "# get the first group\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f6c2946-e40e-41f8-b738-c3b5ad814143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile a pattern to match Release date (hint: non greedy matching)\n",
    " \n",
    "# use the pattern to search\n",
    " \n",
    "# get the first group\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7377951e-6463-4f96-9007-63a04acfdc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile a pattern to match Language (hint: non greedy matching)\n",
    " \n",
    "# use the pattern to search\n",
    " \n",
    "# get the first group\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98720418-a58f-4ead-9186-21bc46fe768a",
   "metadata": {},
   "source": [
    "# Reusable code\n",
    "\n",
    "Now that we've finished our book analysis, let's restructure our code into functions.\n",
    "\n",
    "This will help us re-use the same code again in the future if we're doing a similar analysis\n",
    "\n",
    "The functions we'll create are:\n",
    "1. Read the file and return the lines\n",
    "2. Take the lines and return the text\n",
    "3. Take the text and return a clean list of words\n",
    "4. Take the clean list of words and calculate a count\n",
    "5. Take the count and return the max word\n",
    "6. Take the count and return the min words\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8edd9da8-9947-408e-9d4d-de049d6024d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (749557496.py, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[19], line 17\u001b[0;36m\u001b[0m\n\u001b[0;31m    def lines_to_text(list_of_lines):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# header key phrase\n",
    "header_phrase = \"*** START OF THE PROJECT GUTENBERG EBOOK THE LAND THAT TIME FORGOT ***\"\n",
    "\n",
    "# license key phrase\n",
    "license_phrase = \"End of Project Gutenberg's The Land That Time Forgot, by Edgar Rice Burroughs\"\n",
    "\n",
    "# read a file and return the lines\n",
    "def reader(fname):\n",
    "    # open the file\n",
    "    \n",
    "        # read the lines\n",
    "        \n",
    "        # return the lines\n",
    "       \n",
    "\n",
    "# take the lines and return the text\n",
    "def lines_to_text(list_of_lines):\n",
    "    # join the lines together\n",
    "\n",
    "    # split the header from the rest\n",
    "\n",
    "    # split the text from the license\n",
    "     \n",
    "    # replace multiple newlines with one\n",
    "     \n",
    "    # split on newlines\n",
    "    \n",
    "    #return the lines\n",
    "     \n",
    "\n",
    "# take the lines and return words\n",
    "def lines_to_words(list_of_lines):\n",
    "    # create a list to store the words\n",
    "    \n",
    "    # go through each entry in the list_of_lines\n",
    "     \n",
    "        # add the line split by space to the list of words\n",
    "         \n",
    "    # remove the rest of the header information\n",
    "     \n",
    "    # return the word list\n",
    "     \n",
    "\n",
    "def clean_words(word_list):\n",
    "    # create a list to store cleaned words\n",
    "    \n",
    "    # go through each word in word_list\n",
    "     \n",
    "       # replace the non alphanumeric characters\n",
    "        \n",
    "        # add the cleaned words to the list\n",
    "\n",
    "    # returned the cleaned words\n",
    "\n",
    "    \n",
    "# take the word list and return counts\n",
    "def list_to_count(word_list):\n",
    "    # create a dictionary to store the counts\n",
    "     \n",
    "    # go through each word in word_list\n",
    "     \n",
    "        # if the word is in the dictionary\n",
    "         \n",
    "            # increment the count by one\n",
    "             \n",
    "        # else\n",
    "         \n",
    "            # set the value to 1 for the word\n",
    "            \n",
    "    # return the dictionary\n",
    "     \n",
    "\n",
    "# take the word counts\n",
    "def get_min_word(word_counts):\n",
    "    # use min to calculate the minimum word count\n",
    "     \n",
    "    # create a list to store the words\n",
    "    \n",
    "    # go through the items in the word_counts dictionary\n",
    "     \n",
    "        # if the count matches the minimum\n",
    "         \n",
    "            # add the word to the list\n",
    "             \n",
    "    # return the frequency and the list of words\n",
    "    \n",
    "\n",
    "# run the functions\n",
    "if __name__ == \"__main__\":\n",
    "    # call the function to read the file and return lines\n",
    "     \n",
    "    # call the function that converts lines to text\n",
    "     \n",
    "    # call the function that converts lines to words\n",
    "     \n",
    "    # call the function that cleans the words\n",
    "     \n",
    "\n",
    "    # create a set of the words and output the values\n",
    "\n",
    "    # print the words\n",
    "    print(\"There are {} words in the book and {} of them are unique\")\n",
    "\n",
    "    # call the function that calculates a count from words\n",
    "     \n",
    "\n",
    "    # use max with a key to get the word with the maximum value\n",
    "    \n",
    "    # print the most frequent word and value\n",
    "    print(\"Most frequent word is '{}' with frequency {}\")\n",
    "\n",
    "    # call the function to get the minimum words\n",
    "     \n",
    "    # print the minimum words\n",
    "    print(\"The lowest word_frequency is {} and there are {} words in the book with that word_frequency\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8884e036-ec5a-4b5e-a497-59ad607e682b",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "You'll notice that the numbers output by the script version and the function version are different.\n",
    "\n",
    "This happens often in analysis.  In this particular case, one of the differences is that we didn't remove the `Chapter` from the word list.\n",
    "\n",
    "This is why you'll want to use functions that can be tested so that your code is behaving the way that you expect it will."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3ccaf1-94b0-4b93-94d5-862f5fb3b20e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
