{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "710d0bff-5f42-44cd-b19f-ea951b1dce1c",
   "metadata": {},
   "source": [
    "# Lab 1\n",
    "\n",
    "We will do text analysis of a public free text to demonstrate text analysis techniques.\n",
    "\n",
    "Project Gutenberg is a great resource for these texts.\n",
    "\n",
    "We will use [The Land That Time Forgot](https://www.gutenberg.org/ebooks/551) and download the [TXT version](https://www.gutenberg.org/ebooks/551.txt.utf-8), which we have included in the support files for this training.\n",
    "\n",
    "Take a look at the file and understand the spacing and formatting of the text. \n",
    "\n",
    "**Facilitator: give the learners between 5 and 10 minutes to open the file, and review the text itself. Encourage them to consider the contents: how would they separate the narrative text from the errata that is included in a book? Does the author spell out numbers? Or will they need to figure out how to manage integers inside the text?**\n",
    "\n",
    "There's a boilerplate at the beginning that describes the document and the license at the end for using the text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c37bfc-fa6d-4da9-a4ca-4f02690d9c58",
   "metadata": {},
   "source": [
    "## Count the words of the text\n",
    "\n",
    "We want to count the number of words in the text of the book. \n",
    "\n",
    "To do this we'll split the text on key phrases present in the text.\n",
    "\n",
    "To separate the header from the text, we'll use the phrase\n",
    "`*** START OF THE PROJECT GUTENBERG EBOOK THE LAND THAT TIME FORGOT ***`\n",
    "\n",
    "To separate the text from the license, we'll use the phrase\n",
    "`End of Project Gutenberg's The Land That Time Forgot, by Edgar Rice Burroughs`\n",
    "\n",
    "Since we only want to count words, we'll need to use *regular expressions* to remove punctuation and quotation marks.\n",
    "The only characters we want to keep are alphabetic characters a-z and A-Z.\n",
    "\n",
    "Here is the overview of the steps we're going to take\n",
    "\n",
    "1. Import the `re` module from the Python standard library\n",
    "2. Read in the file from the `./support_files/datasets/land_time_forgot.txt` path\n",
    "3. Split the file into the header and the remainder of the text\n",
    "4. Split the remainder into the text and the license at the end of the novel\n",
    "5. Parse the lines from the text one by one and only keep alphanumeric characters\n",
    "6. Split each line into words and store the words in an array\n",
    "7. Print the length of the array to find the number of words\n",
    "\n",
    "Start with steps 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d7f34fa-87db-42d4-9959-2db74bab3325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the regu from the Python standard library\n",
    "import re\n",
    "\n",
    "# open the file and read it into a variable\n",
    "with open('./support_files/datasets/land_time_forgot.txt') as f:\n",
    "   full_lines = f.readlines()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a226b6-3ad3-47cc-bd5e-5ef011fad19c",
   "metadata": {},
   "source": [
    "What questions can you ask about this data?\n",
    "\n",
    "- How many lines are there in the total file?\n",
    "- How many characters?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57d37528-bc1d-4939-a89f-0fc96848bfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3970\n",
      "220904\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# How many lines in total are there?\n",
    "print(len(full_lines))\n",
    "\n",
    "# How many characters are there?\n",
    "\n",
    "total_count = 0\n",
    "for line in full_lines:\n",
    "    total_count += len(line)\n",
    "    \n",
    "print(total_count)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e2f3da-6a2d-463f-bdda-5f37e2af509e",
   "metadata": {},
   "source": [
    "**Facilitator: do a quick check here to ensure that everyone has the same character count. Occasionally typos can introduce errors. Since we are using a text file that is included in the course there should not be any issues with trying to fetch the text from a remote source**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3408b4c-b823-4208-88d0-f8e2e7f7e910",
   "metadata": {},
   "source": [
    "## Split the file into sections\n",
    "\n",
    "Split the file into the header, the text, and the license\n",
    "\n",
    "If you've used *readlines* or split the text into lines for the previous question, make sure to **[join](https://www.w3schools.com/python/ref_string_join.asp)** the lines together.\n",
    "\n",
    "We want to remove all of the extra new lines before we join the text together again.\n",
    "\n",
    "We'll use **sub** for this purpose with the newline character `\\n` and the `+` to make it substitute all repeating characters.\n",
    "\n",
    "```\n",
    "re.sub(r'\\n+', '\\n', TEXT)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a890bf69-f3f8-4307-985e-93a184de2fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3102"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# header key phrase\n",
    "header_phrase = \"*** START OF THE PROJECT GUTENBERG EBOOK THE LAND THAT TIME FORGOT ***\"\n",
    "\n",
    "# license key phrase\n",
    "license_phrase = \"End of Project Gutenberg's The Land That Time Forgot, by Edgar Rice Burroughs\"\n",
    "\n",
    "# join the lines\n",
    "full_text = \"\".join(full_lines)\n",
    "\n",
    "# separate the header from the rest of the text\n",
    "header, remainder = full_text.split(header_phrase)\n",
    "\n",
    "# separate the text from the license\n",
    "text, license = remainder.split(license_phrase)\n",
    "\n",
    "# remove the extra newlines\n",
    "sub_text = re.sub(r'\\n+', '\\n', text)\n",
    "\n",
    "# how many lines is the text ?\n",
    "text_lines = sub_text.split(\"\\n\")\n",
    "len(text_lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e0ac54-1f25-4f9f-b3b1-bf02559fd08a",
   "metadata": {},
   "source": [
    "**Facilitator: as before this is a good place to stop and make sure everyone has the same number of lines. The regular expression will be the most likely cause of differences.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edbd708-11be-4f38-8f92-2b7185990526",
   "metadata": {},
   "source": [
    "## Verify your work\n",
    "\n",
    "Look at the first 10 lines of the file.  What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50093388-3221-475b-994b-36480a479f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'Produced by Judith Boss.  HTML version by Al Haines.',\n",
       " 'The Land that Time Forgot',\n",
       " 'By',\n",
       " 'Edgar Rice Burroughs',\n",
       " 'Chapter 1',\n",
       " \"It must have been a little after three o'clock in the afternoon that it\",\n",
       " 'happened--the afternoon of June 3rd, 1916.  It seems incredible that',\n",
       " 'all that I have passed through--all those weird and terrifying']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_lines[0:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92211229-ff6e-4610-bbc2-2cfc31b34869",
   "metadata": {},
   "source": [
    "**Eek!**\n",
    "\n",
    "What we see is that there are some header lines still present in the text.\n",
    "\n",
    "We want to remove the empty lines, the Produced by value, and the title and author information.\n",
    "\n",
    "We will keep the chapter information.\n",
    "\n",
    "How many lines do you have to remove from the front of the array?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4041387a-fbc0-449b-8e47-426d7fc3bc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the rest of the header information\n",
    "text_lines = text_lines[5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3efc36d-c09a-40b7-a5e8-4f92da764c6a",
   "metadata": {},
   "source": [
    "## Clean up the text\n",
    "\n",
    "We want to get the words from the text file. This means only keeping the alphabet characters, so use the **sub** function again to only keep those characters.\n",
    "\n",
    "```\n",
    "re.sub('[^a-zA-Z]', '', TEXT)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8382b31f-90ba-4471-b21b-d70108f0a846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Chapter',\n",
       " 'It',\n",
       " 'must',\n",
       " 'have',\n",
       " 'been',\n",
       " 'a',\n",
       " 'little',\n",
       " 'after',\n",
       " 'three',\n",
       " 'o',\n",
       " 'clock',\n",
       " 'in',\n",
       " 'the',\n",
       " 'afternoon',\n",
       " 'that']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define your array of words\n",
    "list_of_words = []\n",
    "\n",
    "# iterate through all of the lines\n",
    "for line in text_lines:\n",
    "    # keep only the alphabet characters\n",
    "    fixed_line = re.sub('[^a-zA-Z]', ' ', line)\n",
    "    # split the line on spaces and add the words onto our array\n",
    "    list_of_words.extend(fixed_line.split())\n",
    "\n",
    "print(len(list_of_words))\n",
    "# look at the first 15 words to verify\n",
    "list_of_words[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90657611-de4d-4c45-b89a-bad8625f7e15",
   "metadata": {},
   "source": [
    "**Facilitator: stop and check. The regex in this step may cause problems. The previous step in which learners needed to remove the first five lines is sometimes skipped.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef5ecce-9dcc-4d03-b0a4-7abd1720aa62",
   "metadata": {},
   "source": [
    "## Additional cleaning\n",
    "\n",
    "The first word is now `Chapter` but there is no number.  We know that there are several of these extraneous words throughout the text.  \n",
    "\n",
    "What other words would you remove from the text?\n",
    "\n",
    "Let's create an array of words that we know from looking at the text shouldn't be counted.\n",
    "\n",
    "Then print the number of words in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5b6d248-4df8-4b2b-874d-8951900509e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words is 37816.\n"
     ]
    }
   ],
   "source": [
    "# create a list of words to skip\n",
    "skip_words = ['Chapter']\n",
    "\n",
    "# create a list that holds the updated text\n",
    "updated_words = []\n",
    "\n",
    "# go through each word in the list\n",
    "for word in list_of_words:\n",
    "    # if it's not in the list of skippable words\n",
    "    if word not in skip_words:\n",
    "        # add the word to the new list that houses the text we want to work with\n",
    "        updated_words.append(word)\n",
    "\n",
    "# print the number of words\n",
    "print(f'Total number of words is {len(updated_words)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2b9332-726d-4261-b516-31145f8dd162",
   "metadata": {},
   "source": [
    "## Data cleanliness\n",
    "\n",
    "When you look at the full text of the book and then the updated_words list, you will find discrepancies or places where you might disagree with the way the words have been split.  For example, in the first 15 lines there are the three words `three` `o` `clock`.  \n",
    "\n",
    "Are these really 3 different words or would you combine `o` and `clock` into one word?\n",
    "\n",
    "When you're analyzing your real data, you'll need to develop hypotheses and rules to clean your data without doing too much to alter the stringency of your analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5266ea2-6c0c-4800-875b-62baaf404b5c",
   "metadata": {},
   "source": [
    "**Facilitator: stop and check. Ensure that all students have the correct number of words.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4bdf72-4e9b-4a8e-b153-67e85bf57fc5",
   "metadata": {},
   "source": [
    "# Word count\n",
    "\n",
    "What is the word that appears most frequently in the text?\n",
    "\n",
    "1. Create a dictionary to store the word as the key and the count as the value\n",
    "2. Go through all of the words\n",
    "3. If the word exists in the dictionary, increment the count\n",
    "4. If the word does not exist, set the count to 1\n",
    "\n",
    "We'll then look at a specific value for a word.  See how many times \"It\" appears in the dictionary\n",
    "\n",
    "Use `get` to find the value.\n",
    "\n",
    "5. Get the max value by using max with a key that indicates it should use `get` for to find the value\n",
    "6. Get the count from the dictionary for the max word\n",
    "7. Print the word and count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae38c62-e32d-4f25-891c-2e18acf50efe",
   "metadata": {},
   "source": [
    "**Faciitator: pay special attention to this section. Counting things is an unexpectedly common operation and the learners will derive a lot of value from knowing how to use a dictionary in this manner.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d3c4c21-0fdd-40bd-8f8c-2eb3aeace152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word It appears 120 times\n",
      "The word that appears most frequently is \"the\" (2,301 times)\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary\n",
    "count_of_words = {}\n",
    "\n",
    "# go through all the words\n",
    "for word in updated_words:\n",
    "    # check if the word is NOT in the dictionary\n",
    "    if count_of_words.get(word) is None:\n",
    "        # set the word in the dictionary to be 1\n",
    "       count_of_words[word] = 1\n",
    "    # else\n",
    "    else:\n",
    "        # increment the count of the word\n",
    "        count_of_words[word] += 1\n",
    "\n",
    "# get the value for \"It\"\n",
    "print(f'The word It appears {count_of_words.get(\"It\")} times')\n",
    "\n",
    "# use max with a key function that gets the dictionary value\n",
    "max_key = max(count_of_words, key=count_of_words.get)\n",
    "\n",
    "max_count = count_of_words[max_key]\n",
    "print('The word that appears most frequently is \"{0:s}\" ({1:5,d} times)'.format(\n",
    "    max_key,max_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6100ca-1a95-44d6-8b2a-c48068a07c3f",
   "metadata": {},
   "source": [
    "## Which words appear the least frequently?\n",
    "\n",
    "Use the `min` method to find the lowest number of times a word appears\n",
    "\n",
    "1. Get the minimum number\n",
    "2. Go through the dictionary\n",
    "3. Check if the count of the key matches the minimum number\n",
    "4. Add the word to the list if it does\n",
    "5. Print the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc08c8a8-a304-4e86-849c-8d299e99c475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum number of times a word appears in the book is 1.0. There are 2494 words with that frequency.\n"
     ]
    }
   ],
   "source": [
    "# Get the minimum frequency (hint: use values)\n",
    "min_freq = float(min(count_of_words.values()))\n",
    "\n",
    "# create a list to store the words\n",
    "min_freq_words = []\n",
    "\n",
    "# Go through all of the word counts (hint: use 'items')\n",
    "for word, count in count_of_words.items():\n",
    "    # check if the value matches the frequency\n",
    "    if count == min_freq:\n",
    "        # add it to the list if it does\n",
    "        min_freq_words.append(word)\n",
    "\n",
    "# Print a sentence of the minimum frequency and the number of words with that frequency\n",
    "print('The minimum number of times a word appears in the book is {}. There are {} words with that frequency.'\n",
    "      .format(min_freq, len(min_freq_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aa51ea-d790-4ae2-bf3e-aa1d594fe98a",
   "metadata": {},
   "source": [
    "**Facilitator: stop and check. Does everyone have the same max and min values? The good news is these are straightforward operations, so the most common issue will be indentation or typos, but the error handler should help the learner in those instances.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d87158b-936c-447b-92b4-bedb68651106",
   "metadata": {},
   "source": [
    "## Stopwords\n",
    "\n",
    "The word that appears the most times is 'the' which is considered a stopword in sentiment analysis.  This word isn't useful to give you an idea of what the text is about so when we do analysis we want to remove these kinds of words.\n",
    "\n",
    "1. Go through the list of stopwords\n",
    "2. remove them from the dictionary of word counts\n",
    "3. find the new word that occurs most frequently\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0353396f-b0d8-4e3c-be75-0958d01d7222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word that appears most frequently is \"all\" (  158 times)\n"
     ]
    }
   ],
   "source": [
    "# stopwords\n",
    "stopwords = [\"a\", \"A\", \"an\", \"and\", \"are\", \"as\", \"at\", \"be\", \"but\", \"for\", \"from\", \n",
    "             \"had\", \"have\", \"he\", \"her\", \"his\", \"if\", \"in\", \"it\", \"I\", \"into\", \"me\", \n",
    "             \"my\", \"of\", \"on\", \"not\", \"she\", \"that\", \"the\", \"to\", \"was\", \"which\", \n",
    "             \"we\", \"were\", \"with\", \"upon\", \"us\"]\n",
    "\n",
    "# go through the list\n",
    "for word in stopwords:\n",
    "    # if the stopword is in the dictionary of word counts\n",
    "    if word in count_of_words:\n",
    "        # remove the word from the dictionary\n",
    "        del count_of_words[word]\n",
    "\n",
    "# get the max key of the word counts again\n",
    "max_key = max(count_of_words, key=count_of_words.get)\n",
    "\n",
    "# get the count of the key\n",
    "max_count = count_of_words[max_key]\n",
    "# print the key and value\n",
    "print('The word that appears most frequently is \"{0:s}\" ({1:5,d} times)'.format(max_key,max_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4163a3a-6eaf-417f-b304-485590625149",
   "metadata": {},
   "source": [
    "## Number of unique words\n",
    "\n",
    "How many unique words are there in the book?\n",
    "\n",
    "Use a `set` to figure this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d326cd0-6edc-4563-abd9-409e1fbac03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This book has 37816 total words and 4962 unique words.\n",
      "The percentage of unique words in the book: 13.1\n"
     ]
    }
   ],
   "source": [
    "# create a set from the words\n",
    "words_set = set(updated_words)\n",
    "\n",
    "# print the number of words\n",
    "print('This book has {} total words and {} unique words.'.format(len(updated_words), len(words_set)))\n",
    "\n",
    "# Print a sentence of the percentage of words that are unique in the book (hint: use :.1f in your format)\n",
    "num_unique_words = len(words_set)\n",
    "num_words = len(updated_words)\n",
    "percentage = (num_unique_words / num_words) * 100\n",
    "print('The percentage of unique words in the book: %.1f' % percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a12529-249d-43d7-893f-0e38c9788a05",
   "metadata": {},
   "source": [
    "**Facilitator: This is another good place to stop. The stopwords list will ideally be copy/pasted but that's no guarantee there won't be a mismatch with the results. Are there other words that should be removed from consideration?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ca4f73-329d-44e6-9043-b348470d8ecb",
   "metadata": {},
   "source": [
    "# Header information\n",
    "\n",
    "Let's examine the header data and identify information using regular expressions.\n",
    "\n",
    "There is a set of lines in the header that have the `Title`, `Author`, `Release date`, and `Language`.\n",
    "\n",
    "Use [search()](https://docs.python.org/3/library/re.html#re.search) to find the data for these fields.\n",
    "\n",
    "You will need to use non-greedy matching to only match the single line\n",
    "\n",
    "https://www.pythoncheatsheet.org/cheatsheet/regular-expressions#greedy-and-non-greedy-matching\n",
    "\n",
    "Make sure the date is just the month, date, and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b85fcdd-8914-4b1d-a9b8-61d259d13b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffThe Project Gutenberg eBook of The Land That Time Forgot\\n    \\nThis ebook is for the use of anyone anywhere in the United States and\\nmost other parts of the world at no cost and with almost no restrictions\\nwhatsoever. You may copy it, give it away or re-use it under the terms\\nof the Project Gutenberg License included with this ebook or online\\nat www.gutenberg.org. If you are not located in the United States,\\nyou will have to check the laws of the country where you are located\\nbefore using this eBook.\\n\\nTitle: The Land That Time Forgot\\n\\nAuthor: Edgar Rice Burroughs\\n\\nRelease date: June 1, 1996 [eBook #551]\\n                Most recently updated: January 1, 2021\\n\\nLanguage: English\\n\\nCredits: Produced by Judith Boss.  HTML version by Al Haines.\\n\\n\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935db82d-a398-43e6-9fc2-8510e9f3cb7e",
   "metadata": {},
   "source": [
    "**Facilitator: if the class has been managing this lab with relative ease, it would be a good challenge to see if the learners can come up with the non-greedy matching script on their own.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b79408c-307f-4506-89d8-da2ee068813e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Land That Time Forgot'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# compile a pattern to match Title (hint: non greedy matching)\n",
    "title_pattern = re.compile(\"Title: (.*?)\\\\n\")\n",
    "# use the pattern to search\n",
    "title_matches = re.search(title_pattern, header)\n",
    "# get the first group\n",
    "title_matches.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04aa3508-d163-412d-be75-2a1c02f6bc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Edgar Rice Burroughs'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile a pattern to match Author (hint: non greedy matching)\n",
    "author_pattern = re.compile(\"Author: (.*?)\\\\n\")\n",
    "# use the pattern to search\n",
    "author_matches = re.search(author_pattern, header)\n",
    "# get the first group\n",
    "author_matches.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f6c2946-e40e-41f8-b738-c3b5ad814143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'June 1, 1996'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile a pattern to match Release date (hint: non greedy matching)\n",
    "rd_pattern = re.compile(\"Release date: (.*?) \\[e\")\n",
    "# use the pattern to search\n",
    "rd_matches = re.search(rd_pattern, header)\n",
    "# get the first group\n",
    "rd_matches.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7377951e-6463-4f96-9007-63a04acfdc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile a pattern to match Language (hint: non greedy matching)\n",
    "language_pattern = re.compile(\"Language: (.*?)\\\\n\")\n",
    "# use the pattern to search\n",
    "language_matches = re.search(language_pattern, header)\n",
    "# get the first group\n",
    "language_matches.group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98720418-a58f-4ead-9186-21bc46fe768a",
   "metadata": {},
   "source": [
    "# Reusable code\n",
    "\n",
    "Now that we've finished our book analysis, let's restructure our code into functions.\n",
    "\n",
    "This will help us re-use the same code again in the future if we're doing a similar analysis\n",
    "\n",
    "The functions we'll create are:\n",
    "1. Read the file and return the lines\n",
    "2. Take the lines and return the text\n",
    "3. Take the text and return a clean list of words\n",
    "4. Take the clean list of words and calculate a count\n",
    "5. Take the count and return the max word\n",
    "6. Take the count and return the min words\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8edd9da8-9947-408e-9d4d-de049d6024d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 37844 words in the book and 4975 of them are unique\n",
      "Most frequent word is 'the' with frequency 2301\n",
      "The lowest word_frequency is 1 and there are 2506 words in the book with that word_frequency\n"
     ]
    }
   ],
   "source": [
    "# header key phrase\n",
    "header_phrase = \"*** START OF THE PROJECT GUTENBERG EBOOK THE LAND THAT TIME FORGOT ***\"\n",
    "\n",
    "# license key phrase\n",
    "license_phrase = \"End of Project Gutenberg's The Land That Time Forgot, by Edgar Rice Burroughs\"\n",
    "\n",
    "# read a file and return the lines\n",
    "def reader(fname):\n",
    "    with open(fname) as file:\n",
    "        lines = file.readlines()\n",
    "        return lines\n",
    "\n",
    "# take the lines and return the text\n",
    "def lines_to_text(list_of_lines):\n",
    "    full_text = \"\".join(full_lines)\n",
    "    header, remainder = full_text.split(header_phrase)\n",
    "    text, license = remainder.split(license_phrase)\n",
    "    sub_text = re.sub(r'\\n+', '\\n', text)\n",
    "    text_lines = sub_text.split(\"\\n\")\n",
    "    return text_lines\n",
    "\n",
    "# take the lines and return words\n",
    "def lines_to_words(list_of_lines):\n",
    "    word_list = []\n",
    "    for line in list_of_lines:\n",
    "        word_list.extend(line.split(\" \"))\n",
    "    # remove the rest of the header information\n",
    "    text_lines = word_list[5:]\n",
    "    return word_list\n",
    "\n",
    "def clean_words(word_list):\n",
    "    list_of_words = []\n",
    "    for line in word_list:\n",
    "       fixed_line = re.sub('[^a-zA-Z]', ' ', line)\n",
    "       list_of_words.extend(fixed_line.split())\n",
    "    return list_of_words\n",
    "\n",
    "# take the word list and return counts\n",
    "def list_to_count(word_list):\n",
    "    word_counts = {}\n",
    "    for word in word_list:\n",
    "        if word in word_counts:\n",
    "            word_counts[word] = word_counts[word] + 1\n",
    "        else:\n",
    "            word_counts[word] = 1\n",
    "    return word_counts\n",
    "\n",
    "# take the word counts\n",
    "def get_min_word(word_counts):\n",
    "    min_word_freq = min(word_counts.values())\n",
    "    min_words = []\n",
    "    for word, fr in word_counts.items():\n",
    "        if fr == min_word_freq:\n",
    "            min_words.append(word)\n",
    "\n",
    "    return min_word_freq, min_words\n",
    "\n",
    "# run the functions\n",
    "if __name__ == \"__main__\":\n",
    "    # call the function to read the file and return lines\n",
    "    my_lines = reader(\"./support_files/datasets/land_time_forgot.txt\")\n",
    "    # call the function that converts lines to text\n",
    "    text_list = lines_to_text(my_lines)\n",
    "    # call the function that converts lines to words\n",
    "    words = lines_to_words(text_list)\n",
    "    # call the function that cleans the words\n",
    "    my_words = clean_words(words)\n",
    "\n",
    "    # create a set of the words and output the values\n",
    "    word_set = set(my_words)\n",
    "    print(\"There are {} words in the book and {} of them are unique\".format(\n",
    "        len(my_words), len(word_set)))\n",
    "\n",
    "    # call the function that calculates a count from words\n",
    "    my_freq = list_to_count(my_words)\n",
    "\n",
    "    # use max with a key to get the word with the maximum value\n",
    "    max_word = max(my_freq, key=my_freq.get)\n",
    "    # print the most frequent word and value\n",
    "    print(\"Most frequent word is '{}' with frequency {}\".format(\n",
    "        max_word, my_freq[max_word]))\n",
    "\n",
    "    # call the function to get the minimum words\n",
    "    mw_freq, mw_list = get_min_word(my_freq)\n",
    "    # print the minimum words\n",
    "    print(\"The lowest word_frequency is {} and there are {} words in the book with that word_frequency\".format(mw_freq, len(mw_list)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff107cf-97c4-480c-9cda-b3146f315eed",
   "metadata": {},
   "source": [
    "**Faciitator: This probably has the most probablility of the learners not coming up with the same results. This is a rather long function. Give them time to work through their errors, and be prepared to do a fair amount of proofreading.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8884e036-ec5a-4b5e-a497-59ad607e682b",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "You'll notice that the numbers output by the script version and the function version are different.\n",
    "\n",
    "This happens often in analysis.  In this particular case, one of the differences is that we didn't remove the `Chapter` from the word list.\n",
    "\n",
    "This is why you'll want to use functions that can be tested so that your code is behaving the way that you expect it will."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
